# Egyptian-Sign-Language-Recognition.
This is our graduation project idea, we developed a vision-based system that can translate Egyptian Sign Language gestures into their corresponding
words and Arabic alphabetic letters. 
The system uses two different architectures for classification:
- A Long Short-Term Memory model(LSTM) was used for Egyptian Sign Language words, and achieved an
accuracy of 0.927. Here the dataset we collected from Asdaa University in Alexandria.
- A Convolutional Neural Network model(CNN) was used for Arabic sign language alphabetic letters, and
achieved an accuracy of 0.90. here's a link of the dataset we used: https://www.kaggle.com/datasets/zssash/zarasl-database-54k 
The model was deployed and tested, and has the potential to improve communication for deaf and hard-of-hearing
people.
